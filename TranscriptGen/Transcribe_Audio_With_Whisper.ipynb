{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR-jeyP-An8"
      },
      "source": [
        "# ‚ú® README\n",
        "\n",
        "This is the companion Colab for the article \"[How to transcribe your audio to text, for free (with SRTs/VTTs!)](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0)\".\n",
        "\n",
        "This Colab shows how to use OpenAI's Whisper to transcribe audio and audiovisual files, and how to save that transcription as a plain text file or as a VTT/SRT caption file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìé Documentation\n",
        "\n",
        "* `input_format`: The source of the audio/video file to be transcribed\n",
        "  * `youtube`: A YouTube video\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "  * `gdrive`: A file in your Google Drive account\n",
        "    * If you select this option, you will need to allow this notebook to connect to your Google Drive account.\n",
        "    * The transcribed file(s) are saved to the same folder as the original file.\n",
        "  * `local`: A local file that you have uploaded to this Colab\n",
        "    * If you select this option, you will need to first upload the file to the Files tab (see Step 1 [here](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozMzc1MzU3)).\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "* `file`: The URL of the YouTube video or the path of the audio file to be transcribed.\n",
        "  * Example: `file = \"https://www.youtube.com/watch?v=AUDIO\"` (transcribing a YouTube video)\n",
        "  * Example: `file = \"/content/drive/My Drive/AUDIO.mp3\"` (transcribing a Google Drive file)\n",
        "  * Example: `file = \"/content/AUDIO.mp3\"` (transcribing a local file)\n",
        "* `plain`: Whether to save the transcription as a text file or not.\n",
        "* `srt`: Whether to save the transcription as an SRT file or not.\n",
        "* `vtt`: Whether to save the transcription as a VTT file or not.\n",
        "* `tsv`: Whether to save the transcription as a TSV (tab-separated values) file or not.\n",
        "* `download`: Whether to download the transcribed file(s) or not.\n"
      ],
      "metadata": {
        "id": "EjLJ6mHptbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üå¥ Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"youtube\" #@param [\"youtube\", \"gdrive\", \"local\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "file = \"https://www.youtube.com/watch?v=6LOwPhPDwVc\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = False #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "download = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "fAQKStuINe3G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# üõ† Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ù Dependencies"
      ],
      "metadata": {
        "id": "hfnRc8yPM79j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad53333-c83e-45a5-ceaa-f17b9608be7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "\n",
        "!pip install -q pytube\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pytube import YouTube\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üëã Whisper configuration\n",
        "\n",
        "This Colab use `medium.en`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ],
      "metadata": {
        "id": "E4eLQzNOo5_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"medium.en\").to(DEVICE)"
      ],
      "metadata": {
        "id": "YCNc3EfV4EIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32d37f9-b71e-4d41-b3de-cce864f0e714"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:17<00:00, 88.8MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üí™ YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ],
      "metadata": {
        "id": "IvN1wRXbo-7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "def download_youtube_audio(url,  file_name = None, out_dir = \".\"):\n",
        "    \"Download the audio from a YouTube video\"\n",
        "    yt = YouTube(url)\n",
        "    if file_name is None:\n",
        "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
        "    yt = (yt.streams\n",
        "            .filter(only_audio = True, file_extension = \"mp4\")\n",
        "            .order_by(\"abr\")\n",
        "            .desc())\n",
        "    return yt.first().download(filename = file_name)"
      ],
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úç Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ],
      "metadata": {
        "id": "ech5wPCwtO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "\n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "\n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "\n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "\n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = Path(file)\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file, verbose = False, language = \"en\")\n",
        "\n",
        "    if plain:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nCreating text file\")\n",
        "\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "\n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ Whisper it!\n",
        "\n",
        "This block actually calls `transcribe_file` üòâ\n"
      ],
      "metadata": {
        "id": "CLC_tpz6tgq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"https://www.youtube.com/watch?v=6LOwPhPDwVc\"\n",
        "\n",
        "if input_format == \"youtube\":\n",
        "    # Download the audio stream of the YouTube video\n",
        "    #print(f\"Downloading audio stream: {audio}\")\n",
        "    audio = download_youtube_audio(file)\n",
        "\n",
        "    # Run Whisper on the audio stream\n",
        "    result = transcribe_file(model, audio, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"gdrive\":\n",
        "    # Authorize a connection between Google Drive and Google Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"local\":\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)"
      ],
      "metadata": {
        "id": "ngTGllHutSfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "36594e6b-ea6f-4963-c1db-e57f516c0255"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: /content/12.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 291145/291145 [08:27<00:00, 574.16frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating VTT file\n",
            "\n",
            "Creating TSV file\n",
            "Downloading /content/12.vtt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02090db9-e135-42fa-9940-81f6cf5592ea\", \"12.vtt\", 73367)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/12.tsv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8d840cd-3b31-4616-8392-e6b0b06d1ace\", \"12.tsv\", 62171)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaapVkdVQqJK",
        "outputId": "617a1d2f-b4e7-4370-e63a-2369e144bc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" Today we're going to learn selection sort. Let's say we're given the following array and we want it sorted in increasing order. How will we do this? During each iteration we'll select the smallest item from the unsorted partition of our array and move it to the sorted partition. We'll keep track of the current minimum and current item with red and blue arrows. Let's get started. We always set the current minimum to the first number in the unsorted partition, in this case 2. We progress the length of the array looking for a smaller number. We find 1 at the end of the array and set it as our current minimum. We swap 1 and 2. We now have one item in our sorted partition. Moving on, we set 8 as our current minimum and scan the remainder of the array for a smaller number, updating the current minimum as we progress. At the end we find 2 and swap it with 8. We're ready for the next iteration. This time 3 moves into our sorted partition. Let's watch the rest of the algorithm play out. Pretty simple. With each iteration you select the smallest item that hasn't yet been sorted. Here's the pseudocode for selection sort. As you can tell from the code and the nested for loop, selection sort has a time complexity of O of n squared, where n is the size of the array. Thank you for watching. Please subscribe and comment suggestions for future videos.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 6.2, 'text': \" Today we're going to learn selection sort. Let's say we're given the following array\", 'tokens': [50363, 6288, 356, 821, 1016, 284, 2193, 6356, 3297, 13, 3914, 338, 910, 356, 821, 1813, 262, 1708, 7177, 50673], 'temperature': 0.0, 'avg_logprob': -0.11869306662647995, 'compression_ratio': 1.7467811158798283, 'no_speech_prob': 0.007956809364259243}, {'id': 1, 'seek': 0, 'start': 6.2, 'end': 11.56, 'text': ' and we want it sorted in increasing order. How will we do this? During each iteration', 'tokens': [50673, 290, 356, 765, 340, 23243, 287, 3649, 1502, 13, 1374, 481, 356, 466, 428, 30, 5856, 1123, 24415, 50941], 'temperature': 0.0, 'avg_logprob': -0.11869306662647995, 'compression_ratio': 1.7467811158798283, 'no_speech_prob': 0.007956809364259243}, {'id': 2, 'seek': 0, 'start': 11.56, 'end': 16.18, 'text': \" we'll select the smallest item from the unsorted partition of our array and move it to the\", 'tokens': [50941, 356, 1183, 2922, 262, 18197, 2378, 422, 262, 5576, 9741, 18398, 286, 674, 7177, 290, 1445, 340, 284, 262, 51172], 'temperature': 0.0, 'avg_logprob': -0.11869306662647995, 'compression_ratio': 1.7467811158798283, 'no_speech_prob': 0.007956809364259243}, {'id': 3, 'seek': 0, 'start': 16.18, 'end': 21.42, 'text': \" sorted partition. We'll keep track of the current minimum and current item with red\", 'tokens': [51172, 23243, 18398, 13, 775, 1183, 1394, 2610, 286, 262, 1459, 5288, 290, 1459, 2378, 351, 2266, 51434], 'temperature': 0.0, 'avg_logprob': -0.11869306662647995, 'compression_ratio': 1.7467811158798283, 'no_speech_prob': 0.007956809364259243}, {'id': 4, 'seek': 0, 'start': 21.42, 'end': 26.72, 'text': \" and blue arrows. Let's get started. We always set the current\", 'tokens': [51434, 290, 4171, 20507, 13, 3914, 338, 651, 2067, 13, 775, 1464, 900, 262, 1459, 51699], 'temperature': 0.0, 'avg_logprob': -0.11869306662647995, 'compression_ratio': 1.7467811158798283, 'no_speech_prob': 0.007956809364259243}, {'id': 5, 'seek': 2672, 'start': 26.72, 'end': 32.8, 'text': ' minimum to the first number in the unsorted partition, in this case 2. We progress the', 'tokens': [50363, 5288, 284, 262, 717, 1271, 287, 262, 5576, 9741, 18398, 11, 287, 428, 1339, 362, 13, 775, 4371, 262, 50667], 'temperature': 0.0, 'avg_logprob': -0.10386176670298856, 'compression_ratio': 1.6163522012578617, 'no_speech_prob': 0.17141886055469513}, {'id': 6, 'seek': 2672, 'start': 32.8, 'end': 47.96, 'text': ' length of the array looking for a smaller number. We find 1 at the end of the array', 'tokens': [50667, 4129, 286, 262, 7177, 2045, 329, 257, 4833, 1271, 13, 775, 1064, 352, 379, 262, 886, 286, 262, 7177, 51425], 'temperature': 0.0, 'avg_logprob': -0.10386176670298856, 'compression_ratio': 1.6163522012578617, 'no_speech_prob': 0.17141886055469513}, {'id': 7, 'seek': 2672, 'start': 47.96, 'end': 54.519999999999996, 'text': ' and set it as our current minimum. We swap 1 and 2. We now have one item in our sorted', 'tokens': [51425, 290, 900, 340, 355, 674, 1459, 5288, 13, 775, 16075, 352, 290, 362, 13, 775, 783, 423, 530, 2378, 287, 674, 23243, 51753], 'temperature': 0.0, 'avg_logprob': -0.10386176670298856, 'compression_ratio': 1.6163522012578617, 'no_speech_prob': 0.17141886055469513}, {'id': 8, 'seek': 5452, 'start': 54.52, 'end': 60.84, 'text': ' partition. Moving on, we set 8 as our current minimum', 'tokens': [50363, 18398, 13, 26768, 319, 11, 356, 900, 807, 355, 674, 1459, 5288, 50679], 'temperature': 0.0, 'avg_logprob': -0.09854747698857234, 'compression_ratio': 1.4275362318840579, 'no_speech_prob': 0.7977882623672485}, {'id': 9, 'seek': 5452, 'start': 60.84, 'end': 65.44, 'text': ' and scan the remainder of the array for a smaller number, updating the current minimum', 'tokens': [50679, 290, 9367, 262, 17675, 286, 262, 7177, 329, 257, 4833, 1271, 11, 19698, 262, 1459, 5288, 50909], 'temperature': 0.0, 'avg_logprob': -0.09854747698857234, 'compression_ratio': 1.4275362318840579, 'no_speech_prob': 0.7977882623672485}, {'id': 10, 'seek': 5452, 'start': 65.44, 'end': 81.4, 'text': ' as we progress. At the end we find 2 and swap it with 8.', 'tokens': [50909, 355, 356, 4371, 13, 1629, 262, 886, 356, 1064, 362, 290, 16075, 340, 351, 807, 13, 51707], 'temperature': 0.0, 'avg_logprob': -0.09854747698857234, 'compression_ratio': 1.4275362318840579, 'no_speech_prob': 0.7977882623672485}, {'id': 11, 'seek': 8140, 'start': 81.4, 'end': 99.52000000000001, 'text': \" We're ready for the next iteration. This time 3 moves into our sorted partition.\", 'tokens': [50363, 775, 821, 3492, 329, 262, 1306, 24415, 13, 770, 640, 513, 6100, 656, 674, 23243, 18398, 13, 51269], 'temperature': 0.0, 'avg_logprob': -0.19209039778936476, 'compression_ratio': 1.0666666666666667, 'no_speech_prob': 0.38198548555374146}, {'id': 12, 'seek': 9952, 'start': 99.52, 'end': 101.36, 'text': \" Let's watch the rest of the algorithm play out.\", 'tokens': [50363, 3914, 338, 2342, 262, 1334, 286, 262, 11862, 711, 503, 13, 50455], 'temperature': 0.0, 'avg_logprob': -0.16510755675179617, 'compression_ratio': 0.9215686274509803, 'no_speech_prob': 0.995315670967102}, {'id': 13, 'seek': 12952, 'start': 129.52, 'end': 144.24, 'text': \" Pretty simple. With each iteration you select the smallest item that hasn't yet been sorted.\", 'tokens': [50363, 20090, 2829, 13, 2080, 1123, 24415, 345, 2922, 262, 18197, 2378, 326, 5818, 470, 1865, 587, 23243, 13, 51099], 'temperature': 0.0, 'avg_logprob': -0.14895363708040607, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.01265872735530138}, {'id': 14, 'seek': 12952, 'start': 144.24, 'end': 150.0, 'text': \" Here's the pseudocode for selection sort. As you can tell from the code and the nested\", 'tokens': [51099, 3423, 338, 262, 25038, 420, 1098, 329, 6356, 3297, 13, 1081, 345, 460, 1560, 422, 262, 2438, 290, 262, 28376, 51387], 'temperature': 0.0, 'avg_logprob': -0.14895363708040607, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.01265872735530138}, {'id': 15, 'seek': 12952, 'start': 150.0, 'end': 156.12, 'text': ' for loop, selection sort has a time complexity of O of n squared, where n is the size of', 'tokens': [51387, 329, 9052, 11, 6356, 3297, 468, 257, 640, 13357, 286, 440, 286, 299, 44345, 11, 810, 299, 318, 262, 2546, 286, 51693], 'temperature': 0.0, 'avg_logprob': -0.14895363708040607, 'compression_ratio': 1.5402298850574712, 'no_speech_prob': 0.01265872735530138}, {'id': 16, 'seek': 15612, 'start': 156.12, 'end': 161.28, 'text': ' the array. Thank you for watching. Please subscribe and comment suggestions for future', 'tokens': [50363, 262, 7177, 13, 6952, 345, 329, 4964, 13, 4222, 12383, 290, 2912, 11776, 329, 2003, 50621], 'temperature': 0.0, 'avg_logprob': -0.2571741017428311, 'compression_ratio': 1.0804597701149425, 'no_speech_prob': 0.9723748564720154}, {'id': 17, 'seek': 15612, 'start': 161.28, 'end': 161.8, 'text': ' videos.', 'tokens': [50621, 5861, 13, 50647], 'temperature': 0.0, 'avg_logprob': -0.2571741017428311, 'compression_ratio': 1.0804597701149425, 'no_speech_prob': 0.9723748564720154}], 'language': 'en'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}